# -*- coding: utf-8 -*-
"""4 CNNs Final-project- mobilenetv4_conv_aa_large.e230_r384_in12k.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UAqE5TjyCYk5mreDjKo3DBzSPClVTkOC
"""

!nvidia-smi

"""##Load Data"""

from google.colab import drive
drive.mount('/content/drive')

#Copy datasets
!cp /content/drive/MyDrive/Datasets/Datasets.zip .

!unzip '/content/Datasets.zip' -d '/content/'

# Count data
import os

# Define the paths to the directories
true_dir = "/content/Datasets/train/true"
false_dir = "/content/Datasets/train/false"

# Use the os module to count the number of files in each directory
true_count = len(os.listdir(true_dir))
false_count = len(os.listdir(false_dir))

# Print the results
print(f"Number of files in {true_dir}: {true_count}")
print(f"Number of files in {false_dir}: {false_count}")

num_true = round(true_count*.15)
num_false = round(false_count*.15)

print(f"Validate for true: {num_true}")
print(f"Validate for false: {num_false}")

import os
import random

# Define the paths to the directories
train_dir = "/content/Datasets/train"
test_dir = "/content/Datasets/test"

val_ratio = 0.2

# Use the os module to count the number of files in each directory
true_count = len(os.listdir(os.path.join(train_dir, "true")))
false_count = len(os.listdir(os.path.join(train_dir, "false")))

# Print the results
print(f"Number of files in true directory: {true_count}")
print(f"Number of files in false directory: {false_count}")

# Define the number of files to select for each test category
num_true = round(true_count * val_ratio)
num_false = round(false_count * val_ratio)

# Define the paths to the source directories for each test category
true_dir = os.path.join(train_dir, "true")
false_dir = os.path.join(train_dir, "false")

# Define the paths to the test directories for each test category
true_test_dir = os.path.join(test_dir, "true")
false_test_dir = os.path.join(test_dir, "false")

# Create the test directories if they don't already exist
os.makedirs(true_test_dir, exist_ok=True)
os.makedirs(false_test_dir, exist_ok=True)

# Set the random seed for reproducibility
random.seed(42)

# Randomly select files from each source directory and move them to the corresponding test directory
true_files = random.sample(os.listdir(true_dir), num_true)
for f in true_files:
    src_file = os.path.join(true_dir, f)
    dst_file = os.path.join(true_test_dir, f)
    os.rename(src_file, dst_file)

false_files = random.sample(os.listdir(false_dir), num_false)
for f in false_files:
    src_file = os.path.join(false_dir, f)
    dst_file = os.path.join(false_test_dir, f)
    os.rename(src_file, dst_file)

import os

# Define the paths to the directories
true_dir = "/content/Datasets/train/true"
false_dir = "/content/Datasets/train/false"

# Use the os module to count the number of files in each directory
true_count = len(os.listdir(true_dir))
false_count = len(os.listdir(false_dir))

# Print the results
print(f"Number of files in {true_dir}: {true_count}")
print(f"Number of files in {false_dir}: {false_count}")

import os

# Define the paths to the directories
true_dir = "/content/Datasets/test/true"
false_dir = "/content/Datasets/test/false"

# Use the os module to count the number of files in each directory
true_count = len(os.listdir(true_dir))
false_count = len(os.listdir(false_dir))

# Print the results
print(f"Number of files in {true_dir}: {true_count}")
print(f"Number of files in {false_dir}: {false_count}")

"""#Install Timm"""

# Install Timm (Need to restart the runtime after finish install )
!pip install git+https://github.com/rwightman/pytorch-image-models.git
!pip install lightning transformers datasets evaluate pillow==9.2.0

import torch
import torch.nn as nn
import torchvision.transforms as T
from torch.utils.data import DataLoader, random_split, Dataset

# Pytorch Image model (TIMM) library: a library for state-of-the-art image classification
import timm
import timm.optim
import timm.scheduler
from timm.data import ImageDataset, create_dataset, create_loader
from timm.data.transforms_factory import create_transform

import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import classification_report
from PIL import Image

import evaluate

import numpy as np
import pandas as pd
from scipy import stats

from tqdm.notebook import tqdm

import glob

from sklearn.model_selection import StratifiedKFold,KFold

from lightning.fabric import Fabric

from copy import copy

import shutil

from sklearn.utils.class_weight import compute_class_weight

"""##visualization Model"""

try:
    from torchinfo import summary
except:
    print("[INFO] Couldn't find torchinfo... installing it.")
    !pip install -q torchinfo
    from torchinfo import summary

# Select model
model_name = "hf_hub:timm/mobilenetv4_conv_aa_large.e230_r384_in12k_ft_in1k"
model = timm.create_model(model_name, pretrained=True, num_classes=4)

# Print a summary using torchinfo (uncomment for actual output)
summary(model=model, # Use the 'model' variable here
        input_size=(16, 3, 224, 224),
        col_names=["input_size", "output_size", "num_params", "trainable"],
        col_width=20,
        row_settings=["var_names"]
)

# !pip install torchviz

# from torchviz import make_dot
# import os
# # Create a dummy input
# x = torch.randn(1, 3, 224, 224).requires_grad_(True)
# y = efficientnet_b7_model(x)
# graph= make_dot(y, params=dict(list(efficientnet_b7_model.named_parameters()) + [('x', x)]))
# graph.render(filename='model_graph', directory=os.getcwd(), format='png')
# # Visualize the model as a graph

# # graph = make_dot(efficientnet_b7_model(x), params=dict(efficientnet_b7_model.named_parameters()))
# # graph = make_dot(efficientnet_b7_model(x), params=dict(efficientnet_b7_model.named_parameters()), show_attrs=True, show_saved=True)

# # Save the graph visualization to a file
# # graph.render(filename='model_graph', directory=os.getcwd(), format='png')

# from torchviz import make_dot
# import os
# # Create a dummy input
# x = torch.randn(1, 3, 224, 224).requires_grad_(True)

# graph = make_dot(efficientnet_b7_model(x), params=dict(efficientnet_b7_model.named_parameters()))
# # graph = make_dot(efficientnet_b7_model(x), params=dict(efficientnet_b7_model.named_parameters()), show_attrs=True, show_saved=True)

# # Save the graph visualization to a file
# graph.render(filename='model_graph3', directory=os.getcwd(), format='png')

# Transform image data based on ImageNet's mean and std
transforms = {
    "train": T.Compose([
        T.Resize((224, 224)),
        T.ToTensor(),
        T.Normalize(mean=torch.tensor([0.4850, 0.4560, 0.4060]), std=torch.tensor([0.2290, 0.2240, 0.2250]))
    ]),
    "test": T.Compose([
        T.Resize((224, 224)),
        T.ToTensor(),
        T.Normalize(mean=torch.tensor([0.4850, 0.4560, 0.4060]), std=torch.tensor([0.2290, 0.2240, 0.2250]))
    ])
}

train_dir = '/content/Datasets/train'
# test_dir = '/content/Datasets/test'

# Use ImageFolder to create dataset(s)
from torchvision import datasets
dataset = datasets.ImageFolder(root=train_dir, # target folder of images
                                  transform=transforms["train"], # transforms to perform on data (images)
                                  target_transform=None) # transforms to perform on labels (if necessary)

dataset.class_to_idx

len(dataset)

# Select device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
device

#Select Model
model_name = "hf_hub:timm/tf_efficientnet_b7.ns_jft_in1k"

num_epochs = 5
criterion = nn.CrossEntropyLoss()

# Cross Validation Configuration
k_splits = 5
metric = evaluate.load("accuracy")

# Cross validation
kf = KFold(n_splits=k_splits, shuffle=True, random_state=42)

# Gradient Accumulation Settings
# Set to 1 for no accumulation
train_batch_size = 16
eval_batch_size = 8
num_accumulate = 1

torch.set_float32_matmul_precision('high')
fabric = Fabric(accelerator="cuda", precision="16-mixed")
fabric.launch()

import time

# Commented out IPython magic to ensure Python compatibility.
# %%time
# all_eval_scores = []
# 
# for fold, (train_idx, val_idx) in enumerate(kf.split(dataset)):
#     print(f"Fold {fold+1} of {k_splits}")
# 
#     # Load Model
#     model = timm.create_model(model_name, pretrained=True, num_classes=3)
# 
# 
#     # Load Optimizer and Scheduler
#     optimizer = timm.optim.create_optimizer_v2(model, opt="AdamW", lr=5e-4)
#     # optimizer = timm.optim.Lookahead(optimizer, alpha=0.5, k=6)    # update the slow weight every k steps
#                                                                    # update the optimizer by combine slow weight and fast weight * alpha
# 
#     model, optimizer = fabric.setup(model, optimizer)
# 
#     scheduler = timm.scheduler.create_scheduler_v2(optimizer, num_epochs=num_epochs)[0]
# 
#     # Load Data: split train and valition set based on kfold
#     train_dataset = torch.utils.data.Subset(dataset, train_idx)
#     val_dataset = torch.utils.data.Subset(dataset, val_idx)
# 
#     train_dataloader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=4, pin_memory=True)
#     val_dataloader = DataLoader(val_dataset, batch_size=eval_batch_size, shuffle=False, num_workers=4, pin_memory=True)
# 
#     train_dataloader, val_dataloader = fabric.setup_dataloaders(train_dataloader, val_dataloader)
# 
#     # Reset Model Info
#     info = {
#         "metric_train": [],
#         "metric_val": [],
#         "train_loss": [],
#         "val_loss": [],
#         "best_metric_val": -999,
#         "best_val_loss": 999,
#     }
# 
#     for epoch in range(num_epochs):
#         train_loss_epoch = []
#         val_loss_epoch = []
# 
#         train_preds = []
#         train_targets = []
# 
#         val_preds = []
#         val_targets = []
# 
#         num_updates = epoch * len(train_dataloader)
# 
#         ### === Train Loop === ###
#         ## Time
#         s1 = time.time()
# 
#         model.train()
#         for idx, batch in enumerate(tqdm(train_dataloader)):
#             inputs, targets = batch
#             # inputs = {k: v.to(device) for k,v in inputs.items()}
#             outputs = model(inputs)
#             loss = criterion(outputs, targets)
# 
#             fabric.backward(loss)
# 
#             # === Gradient Accumulation === #
#             if ((idx + 1) % num_accumulate == 0) or (idx + 1 == len(train_dataloader)):
#                 optimizer.step()
#                 scheduler.step_update(num_updates=num_updates)
#                 optimizer.zero_grad()
#             # ============================= #
# 
#             train_loss_epoch.append(loss.item())
#             train_preds += outputs.argmax(-1).detach().cpu().tolist()
#             train_targets += targets.tolist()
#         ### ==================== ###
# 
#         # optimizer.sync_lookahead()              # Sync slow weight and fast weight
#         scheduler.step(epoch + 1)
# 
#         ### === Evaluation Loop === ###
#         model.eval()
#         with torch.no_grad():
#             for batch in tqdm(val_dataloader):
#                 inputs, targets = batch
#                 # inputs = {k: v.to(device) for k,v in inputs.items()}
#                 outputs = model(inputs)
#                 loss = criterion(outputs, targets)
# 
#                 # Log Values
#                 val_loss_epoch.append(loss.item())
#                 val_preds += outputs.argmax(-1).detach().cpu().tolist()
#                 val_targets += targets.tolist()
#         ### ======================= ###
#         ## Time train finish
#         s2 = time.time()
#         elapsed_time = s2 - s1
# 
# 
#         # Log Data
#         metric_train = metric.compute(predictions=train_preds, references=train_targets)["accuracy"]
#         metric_val = metric.compute(predictions=val_preds, references=val_targets)["accuracy"]
# 
#         info["metric_train"].append(metric_train)
#         info["metric_val"].append(metric_val)
# 
#         info["train_loss"].append(np.average(train_loss_epoch))
#         info["val_loss"].append(np.average(val_loss_epoch))
# 
#         if metric_val > info["best_metric_val"]:
#         # if info["val_loss"][-1] < info["best_val_loss"]:
#             print("New Best Score!")
#             # print("New Best Val Loss")
#             info["best_metric_val"] = metric_val
#             # info["best_val_loss"] = info["val_loss"][-1]
#             torch.save(model, f"efficientnet_checkpoint_fold{fold}.pt")
# 
#         print(f"Using time of Fold: {fold} | Epoch: {epoch} | {elapsed_time} second ")
#         print(info)
#         print(f"Fold: {fold} | Epoch: {epoch} | Metric: {metric_val} | Training Loss: {np.average(train_loss_epoch)} | Validation Loss: {np.average(val_loss_epoch)}")
# 
#     # save all best metric val
#     all_eval_scores.append(info["best_metric_val"])
#

classname = dataset.classes
classname

for fold in range(k_splits):
    predictions = []
    references = []

    # load model
    loaded_model = torch.load(f"efficientnet_checkpoint_fold{fold}.pt")
    # Evaluation
    loaded_model.eval()
    with torch.no_grad():
        for batch in tqdm(val_dataloader):
            inputs, targets = batch
            outputs = loaded_model(inputs.to(device))

            # Log Values
            predictions += outputs.argmax(-1).detach().cpu().tolist()
            references += targets.tolist()

    print(f"Fold: {fold}")

    # Confusion matrix
    cm = confusion_matrix(references, predictions)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=classname)
    disp.plot()
    plt.show()

    # Classification Report
    print(classification_report(references, predictions, target_names=classname))

classname = dataset.classes
classname

"""###Verification by sepreate data"""

test_folder = '/content/Datasets/test'

# Making Dataset
from torchvision import datasets
test_dataset = datasets.ImageFolder(root=test_folder, # target folder of images
                                  transform=transforms["test"], # transforms to perform on data (images)
                                  target_transform=None) # transforms to perform on labels (if necessary)

len(test_dataset)

# Making test dataloader
test_dataloader = DataLoader(test_dataset, batch_size=eval_batch_size, shuffle=False, num_workers=4, pin_memory=True)

test_dataset.classes

len(test_dataloader)

for fold in range(k_splits):
    predictions = []
    references = []

    # load model
    loaded_model = torch.load(f"efficientnet_checkpoint_fold{fold}.pt")
    # Evaluation
    loaded_model.eval()
    with torch.no_grad():
        for batch in tqdm(test_dataloader):
            inputs, targets = batch
            outputs = loaded_model(inputs.to(device))

            # Log Values
            predictions += outputs.argmax(-1).detach().cpu().tolist()
            references += targets.tolist()

    print(f"Fold: {fold}")

    # Confusion matrix
    cm = confusion_matrix(references, predictions)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=classname)
    disp.plot()
    plt.show()

    # Classification Report
    print(classification_report(references, predictions, target_names=classname))

"""##Visualization train model result"""

## Making Pridcition return class & prob
from typing import List, Tuple

from PIL import Image
def pred_class(model: torch.nn.Module,
                        image_path: str,
                        class_names: List[str],
                        image_size: Tuple[int, int] = (224, 224),
                        transform: T = None,
                        device: torch.device=device):


    # 2. Open image
    img = Image.open(image_path)

    # 3. Create transformation for image (if one doesn't exist)
    if transform is not None:
        image_transform = transform
    else:
        image_transform = transforms.Compose([
            transforms.Resize(image_size),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                 std=[0.229, 0.224, 0.225]),
        ])

    ### Predict on image ###

    # 4. Make sure the model is on the target device
    model.to(device)

    # 5. Turn on model evaluation mode and inference mode
    model.eval()
    with torch.inference_mode():
      # 6. Transform and add an extra dimension to image (model requires samples in [batch_size, color_channels, height, width])
      transformed_image = image_transform(img).unsqueeze(dim=0)

      # 7. Make a prediction on image with an extra dimension and send it to the target device
      target_image_pred = model(transformed_image.to(device))

    # 8. Convert logits -> prediction probabilities (using torch.softmax() for multi-class classification)
    target_image_pred_probs = torch.softmax(target_image_pred, dim=1)

    # 9. Convert prediction probabilities -> prediction labels
    target_image_pred_label = torch.argmax(target_image_pred_probs, dim=1)

    classname =  class_names[target_image_pred_label]
    prob = target_image_pred_probs.max().cpu().numpy()

    return classname , prob

##Load some model
loaded_model = torch.load('/content/efficientnet_checkpoint_fold4.pt')

"""##Train data visulization"""

#Making df for random
import os
import pandas as pd
from PIL import Image

# create an empty list to store image paths
image_paths = []

# loop through each subfolder in the "Image" directory
for root, dirs, files in os.walk('/content/Datasets/test'):
    for subfolder_name in dirs:
        # get the path to the subfolder
        subfolder_path = os.path.join(root, subfolder_name)
        # loop through each file in the subfolder
        for filename in os.listdir(subfolder_path):
            image_path = os.path.join(subfolder_path, filename)
            image_paths.append((image_path, subfolder_name))

# create a DataFrame from the list of image paths
df = pd.DataFrame(image_paths, columns=['path', 'subfolder_name'])

df.head()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image



def sample_picture(df=df,random_state=None):
    # Sample 20 random rows from the DataFrame
    sample_df = df.sample(20, random_state=random_state).copy()
    sample_df = sample_df.reset_index(drop=True)
    # Define the grid layout for displaying the images
    num_rows = 4
    num_cols = 5
    fig, axs = plt.subplots(num_rows, num_cols, figsize=(15, 12))
    fig.tight_layout(pad=5.0)

    # Iterate over the sampled rows and display the images in the grid
    for i, row in sample_df.iterrows():
        img = Image.open(row['path'])

        # Prediction
        pred_name , prob = pred_class(model=loaded_model,image_path=row['path'],
                   class_names = classname,
                   transform=transforms["test"])

        row_idx = i // num_cols
        col_idx = i % num_cols
        axs[row_idx, col_idx].imshow(img)
        axs[row_idx, col_idx].axis('on')
        axs[row_idx, col_idx].set_title(row['subfolder_name'] + ': \nPredict:' + pred_name + '\nProb:'+ str(prob.round(decimals=2)) )

        # prediction


    plt.show()

sample_picture()

sample_picture()

sample_picture()

"""## Outsite data testing"""

!wget https://universe.roboflow.com/ds/fx3tNSqjNJ?key=N4VBuJEAJf

!unzip /content/fx3tNSqjNJ?key=N4VBuJEAJf

import pandas as pd
train_df = pd.read_csv('/contents/train/_classes.csv')

#Count all value in train data set
train_df[(train_df == 1)].sum()

#Sum all Sphere fiber fragment sheet sum = 1 if one class sum >1 is multiclass
train_df['Sum'] = train_df[' Sphere'] + train_df[' fiber'] + train_df[' fragment'] + train_df[' sheet']

# Count Multiclass pictures
train_df[(train_df['Sum']> 1)].count()

# Delete multiclass picture
train_df = train_df[train_df['Sum'] == 1]

# Count remain
train_df[(train_df == 1)].sum()

# Seperate in to dataset/Sphere , dataset/fiber, dataset/fragment, dataset/sheet,
import os
import shutil

# read the file names and classes into a pandas dataframe
df =train_df

# define the source and destination directories
src_dir = '/content/train'
dst_dir = '/content/dataset'

# loop through each row in the dataframe
for idx, row in df.iterrows():
    # get the filename and class label
    filename = row['filename']

    # check if the class label is 1
    if row[' Sphere'] == 1:
        # create the destination directory if it doesn't exist
        dst_subdir = os.path.join(dst_dir,'Sphere')
        os.makedirs(dst_subdir, exist_ok=True)

        # copy the file to the destination directory
        src_path = os.path.join(src_dir, filename)
        dst_path = os.path.join(dst_subdir, filename)
        shutil.copyfile(src_path, dst_path)
    elif row[' fiber'] == 1:
        # create the destination directory if it doesn't exist
        dst_subdir = os.path.join(dst_dir, 'fiber')
        os.makedirs(dst_subdir, exist_ok=True)

        # copy the file to the destination directory
        src_path = os.path.join(src_dir, filename)
        dst_path = os.path.join(dst_subdir, filename)
        shutil.copyfile(src_path, dst_path)
    elif row[' fragment'] == 1:
        # create the destination directory if it doesn't exist
        dst_subdir = os.path.join(dst_dir, 'fragment')
        os.makedirs(dst_subdir, exist_ok=True)

        # copy the file to the destination directory
        src_path = os.path.join(src_dir, filename)
        dst_path = os.path.join(dst_subdir, filename)
        shutil.copyfile(src_path, dst_path)
    elif row[' sheet'] == 1:
        # create the destination directory if it doesn't exist
        dst_subdir = os.path.join(dst_dir, 'sheet')
        os.makedirs(dst_subdir, exist_ok=True)

        # copy the file to the destination directory
        src_path = os.path.join(src_dir, filename)
        dst_path = os.path.join(dst_subdir, filename)
        shutil.copyfile(src_path, dst_path)

#Making df of another for random
import os
import pandas as pd
from PIL import Image

# create an empty list to store image paths
image_paths = []

# loop through each subfolder in the "Image" directory
for root, dirs, files in os.walk('/content/dataset'):
    for subfolder_name in dirs:
        # get the path to the subfolder
        subfolder_path = os.path.join(root, subfolder_name)
        # loop through each file in the subfolder
        for filename in os.listdir(subfolder_path):
            image_path = os.path.join(subfolder_path, filename)
            image_paths.append((image_path, subfolder_name))

# create a DataFrame from the list of image paths
other_df = pd.DataFrame(image_paths, columns=['path', 'subfolder_name'])

other_df.head()

sample_picture(df=other_df)

sample_picture(df=other_df)

sample_picture(df=other_df)

sample_picture(df=other_df)

sample_picture(df=other_df)

sample_picture(df=other_df)

sample_picture(df=other_df)

sample_picture(df=other_df)

sample_picture(df=other_df)

sample_picture(df=other_df)

sample_picture(df=other_df)

sample_picture(df=other_df)

!cp /content/efficientnet_checkpoint_fold0.pt /content/drive/MyDrive/Datasets/Trial12_efficentnet
!cp /content/efficientnet_checkpoint_fold1.pt /content/drive/MyDrive/Datasets/Trial12_efficentnet
!cp /content/efficientnet_checkpoint_fold2.pt /content/drive/MyDrive/Datasets/Trial12_efficentnet
!cp /content/efficientnet_checkpoint_fold3.pt /content/drive/MyDrive/Datasets/Trial12_efficentnet
!cp /content/efficientnet_checkpoint_fold4.pt /content/drive/MyDrive/Datasets/Trial12_efficentnet

!nvidia-smi